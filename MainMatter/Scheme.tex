\chapter{Esquema de la restauraci\'on de im\'agenes}\label{chapter:scheme}

\section{Esquema inicial}
Primeramente se introduce el esquema principal de esta propuesta para la restauraci\'on de im\'agenes presentada en \cite{ram2013image}. Para ello se considera la siguiente notaci\'on:
\begin{itemize}
	\item $\Z$: matriz que representa la imagen incompleta a recuperar (ver epígrafe \ref{sec:digital_images}), de dimensi\'on $N_1 \times N_2$, $N_1N_2 = N$.
	\item $\z$: versión en forma de vector (o señal) de la matriz $\Z$ (ver epigrafe \ref{sec:signals}), de dimensi\'on $N \times 1$.
	\item $\P$: matriz de permutaci\'on (ver epigrafe \ref{sec:permutation_matrices}) de dimensi\'on $N \times N$.
\end{itemize}
Para obtener la señal recuperada $\yhat$ a partir de $\z$ se procede de la siguiente forma:
\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\node (z) at (0, 0) {$\z$};
		\node (P) at (3, 0) {$\boxed{\P}$};
		\node at ($(P)+(0,-1)$) {\centering Permutaci\'on};
		\node (H) at (7, 0) {$\boxed{\H}$};
		\node at ($(H)+(0,-1)$) {\parbox{3cm}{\centering Operador de suavidad}};
		\node (Pinv) at (11, 0) {$\boxed{\P^{-1}}$};
		\node at ($(Pinv)+(0,-1)$) {\parbox{3cm}{\centering Permutaci\'on inversa}};
		\node (yhat) at (14, 0) {$\yhat$};
		\draw [-stealth] ($(z)+(.5,0)$) -- ($(P)+(-1,0)$);
		\draw [-stealth] ($(P)+(1,0)$) -- ($(H)+(-1,0)$);
		\draw [-stealth] ($(H)+(1,0)$) -- ($(Pinv)+(-1,0)$);
		\draw [-stealth] ($(Pinv)+(1,0)$) -- ($(yhat)+(-.5,0)$);
	\end{tikzpicture}
	\caption{Esquema inicial.}
	\label{fig:init_scheme}
\end{figure}
Al premultiplicar $\P$ por el vector $\z$ se reordenan sus elementos seg\'un dicha permutaci\'on. Luego a la señal resultante $\z^p$ se le aplica un operador de suavidad $\H$ con el cual se obtienen los elementos faltantes. Finalmente el vector resultante se permuta mediante $\P^{-1}=\P^\intercal$ (lema \ref{lm:inverse_permutation}), colocando todos sus elementos en su posici\'on inicial en $\z$. En el ejemplo \ref{ex:init_scheme} se muestra de forma sencilla c\'omo aplicar paso por paso este esquema\footnote{La matriz $\P$ y el operador $\H$ empleados en este ejemplo son solamente ilustrativos.}. El vector restaurado resultante $\yhat$ puede expresarse como:
\begin{equation}
	\yhat = \P^{-1}\H(\z^p) = \P^{-1}\H(\P\z)
	\label{eq:init_yhat}
\end{equation}

\begin{example}[H]
	\[
	\Z = \left(
		\begin{matrix}
			9 & \boxed{?} & 25\\
			\boxed{?} &  1 & 81\\
			16 &  4 & 36\\
		\end{matrix}
	\right)
	\longrightarrow
	\z = \left(
		\begin{matrix}
			9 \\ \boxed{?} \\ 16 \\ \boxed{?} \\ 1 \\ 4 \\ 25 \\ 81 \\ 36\\
		\end{matrix}
	\right)
	\qquad
	\P = \left(
		\begin{matrix}
			0&0&0&0&1&0&0&0&0\\
			0&0&0&0&0&1&0&0&0\\
			1&0&0&0&0&0&0&0&0\\
			0&0&1&0&0&0&0&0&0\\
			0&0&0&0&0&0&1&0&0\\
			0&0&0&0&0&0&0&0&1\\
			0&1&0&0&0&0&0&0&0\\
			0&0&0&1&0&0&0&0&0\\
			0&0&0&0&0&0&0&1&0\\
		\end{matrix}
	\right)
	\]
	\centering{
	\begin{tikzpicture}
		\node (z) at (0, 0) {$\left(\begin{matrix}9\\\boxed{?}\\16\\\boxed{?}\\1\\4\\25\\81\\36\\\end{matrix}\right)$};
		\node at ($(z)+(0,-3)$) {$\z$};
		\node (P) at (4, 0) {$\left(\begin{matrix}1\\4\\9\\16\\25\\36\\\boxed{?}\\\boxed{?}\\81\end{matrix}\right)$};
		\node at ($(P)+(0,-3)$) {$\P\z = \z^p$};
		\node (H) at (8, 0) {$\left(\begin{matrix}1\\4\\9\\16\\25\\36\\\boxed{49}\\\boxed{64}\\81\end{matrix}\right)$};
		\node at ($(H)+(0,-3)$) {$\H(\z^p)$};
		\node (Pinv) at (12, 0) {$\left(\begin{matrix}9\\\boxed{49}\\16\\\boxed{64}\\1\\4\\25\\81\\36\end{matrix}\right)$};
		\node at ($(Pinv)+(0,-3)$) {$\P^{-1}\H(\z^p)  = \yhat$};
		\draw [-stealth] ($(z)+(1,0)$) -- ($(P)+(-1,0)$);
		\draw [-stealth] ($(P)+(1,0)$) -- ($(H)+(-1,0)$);
		\draw [-stealth] ($(H)+(1,0)$) -- ($(Pinv)+(-1,0)$);
	\end{tikzpicture}}
	\[
	\P^{-1} = \P^\intercal = \left(
		\begin{matrix}
			0&0&1&0&0&0&0&0&0\\
			0&0&0&0&0&0&1&0&0\\
			0&0&0&1&0&0&0&0&0\\
			0&0&0&0&0&0&0&1&0\\
			1&0&0&0&0&0&0&0&0\\
			0&1&0&0&0&0&0&0&0\\
			0&0&0&0&1&0&0&0&0\\
			0&0&0&0&0&0&0&0&1\\
			0&0&0&0&0&1&0&0&0\\
		\end{matrix}
	\right)
	\qquad
	\yhat = \left(
		\begin{matrix}
			9\\\boxed{49}\\16\\\boxed{64}\\1\\4\\25\\81\\36
		\end{matrix}
	\right)
	\longrightarrow
	\Yhat = \left(
		\begin{matrix}
			9 & \boxed{64} & 25\\
			\boxed{49} &  1 & 81\\
			16 &  4 & 36\\
		\end{matrix}
	\right)
	\]
	\caption{Esquema inicial aplicado a una matriz de $3 \times 3$.}
	\label{ex:init_scheme}
\end{example}

Para comprender mejor lo que se quiere lograr con este procedimiento supongamos que contamos con la imagen real, la versi\'on de $\Z$ con la informaci\'on todos sus p\'ixeles. Aunque en la pr\'actica esta imagen no existe, la utilizaremos para reflejar de forma clara el funcionamiento del esquema inicial (figura \ref{fig:init_scheme}). Se consideran los siguientes elementos:
\begin{itemize}
	\item $\Y$: matriz de la imagen original, es igual a $\Z$ y adem\'as tiene el valor de sus p\'ixeles faltantes. 
	\item $\y$: versión en forma de vector (o señal) de la matriz $\Y$.
\end{itemize}
Supongamos adem\'as que la matriz de permutaci\'on $\P$ tiene la propiedad de que al premultiplicarse por $\y$ se obtiene una señal suave $\y^p$. Por otro lado, se tiene que $\z^p$ y $\y^p$ solo difieren en los p\'ixeles faltantes de $\Z$, y que $\H(\z^p)$ completa la señal, haciéndola suave. Se puede esperar entonces que $\yhat$ sea una aproximaci\'on de $\y$. Lo anterior expresado formalmente:
\begin{equation}
	\def\arraystretch{1.5}
	\begin{array}{lrcl}
		                                       &     \H (\P\z ) &\approx& \P\y        \\ 
		\Longrightarrow                        & P^{-1}\H(\P\z) &\approx& \P^{-1}\P\y \\
		\overset{(\ref{eq:init_yhat})}{\Longrightarrow} & \yhat &\approx& \y          \\
	\end{array}
	\label{eq:permutation_smoothness}
\end{equation}
El objetivo de la restauraci\'on no es m\'as que encontrar una aproximaci\'on de esa imagen real que desconocemos, por lo tanto este resultado valida el funcionamiento del esquema (figura \ref{fig:init_scheme}).

Llegados a este punto las únicas incógnitas son qu\'e operador $\H$ usar, y c\'omo obtener la matriz $\P$. Operadores para suavizar en \textbf{1D} se conocen varios en la literatura, por ejemplo, los que se usan para interpolaci\'on o filtrado. Por el momento consideremos este operador como un par\'ametro del esquema. Para el caso de $\P$, en el siguiente ep\'igrafe se expone c\'omo hacer para obtener esta permutaci\'on.

\section{La matriz de permutaci\'on}

El resultado (\ref{eq:permutation_smoothness}) tiene como condici\'on que $\y^p$ sea una señal suave. Para calcular la suavidad de $\y^p$ se usa la varianza total (definici\'on \ref{def:tv}) \cite{greenhall1999total}, que en este caso resulta:
\begin{equation}
	\|\y^p\|_{\mathit{TV}} = \sum_{j = 2}^{N}|\y^{p}(j) - \y^{p}(j - 1)|
	\label{eq:signal_smoothness}
\end{equation}
La matriz $\P$ que se busca es tal que minimiza $\|\y^p\|_{\mathit{TV}}$, recordemos que no se cuenta con la señal  $\y$, entonces calcular $|\y^{p}(j) - \y^{p}(j - 1)|$ solo es posible cuando ambos elementos est\'an en la imagen incompleta $\Z$, lo que significa que se conoce su valor.

Para encontrar la distancia entre dos p\'ixeles de $\Z$ (independientemente de si se conoce su valor o no) usaremos sus parches (ver epígrafe \ref{sec:patches}) de la siguiente manera:
\begin{equation}
	|\y^{p}(j) - \y^{p}(j - 1)| \equiv \omega(\x_j^p,\; \x_{j - 1}^p)
	\label{eq:omega_measure}
\end{equation}
donde $\x_j^p$ denota el parche de $\Z$ cuyo p\'ixel central es denotado por $\z^p(j)$. Y $\omega$ es una funci\'on de distancia definida sobre los parches la cual cumple que para cualesquiera dos parches, proximidad entre ellos sugiere proximidad entre sus p\'ixeles centrales, tal como se expresa en (\ref{eq:omega_measure}). Luego, usando (\ref{eq:omega_measure}) en (\ref{eq:signal_smoothness}), el problema de minimizar $\|\y^p\|_{\mathit{TV}}$ es equivalente a:
\begin{equation}
	\begin{array}{ccc}
		\displaystyle\min_\P \|\X^p\|_{\mathit{TV}} & \mbox{donde} & \|\X^p\|_{\mathit{TV}}  = \displaystyle\sum_{j = 2}^{N}\omega(\x_j^{p},\; \x_{j - 1}^{p})
	\end{array}
	\label{eq:path_smoothness}
\end{equation}
tal que $\X$ denota el vector de los parches de $\Z$ (ver ejemplo \ref{ex:vector_X}) y $\X^p$ una permutaci\'on de $\X$ dada por una matriz $\P$. La soluci\'on de este problema de optimizacion es la matriz $\P$ que se busca.
\begin{example}[H]
	\[\Z = \left(
		\begin{matrix}
			a & b & c & d\\\cline{2-3}
			e & \multicolumn{1}{|c}{f} & \multicolumn{1}{c|}{g} & h\\
			i & \multicolumn{1}{|c}{j} & \multicolumn{1}{c|}{k} & l\\\cline{2-3}
			m & n & o & p\\
		\end{matrix}
	\right)
	\qquad\z = \left(
		\begin{array}{ccccc|cc|cc|cc|ccccc}
			\cline{6-7}\cline{10-11}
			a & e & i & m & b & f & j & n & c & g & k & o & d & h & l & p \\
			\cline{6-7}\cline{10-11}
		\end{array}
	\right)^\intercal\]
	\[\X = \left(
		\begin{matrix}\cline{5-5}
			a & e & i & b & \multicolumn{1}{|c|}{f} & j & c & g & k\\
			e & i & m & f & \multicolumn{1}{|c|}{j} & n & g & k & o\\
			b & f & j & c & \multicolumn{1}{|c|}{g} & k & d & h & l\\
			f & j & n & g & \multicolumn{1}{|c|}{k} & o & h & l & p\\\cline{5-5}
		\end{matrix}
	\right)\]
	\caption{Vector de parches $\X$ de una matriz $\Z$ de $4 \times 4$, y parches de $2 \times 2$. Se resalta el $5^{to}$ parche.}
	\label{ex:vector_X}
\end{example}

Ahora bien, el problema de optimizaci\'on anterior se puede reformular de la siguiente forma. Sea $G_\X \langle V,\;E,\;f\rangle$ un grafo ponderado y completo \cite{west2001introduction} tal que:
\begin{itemize}
	\item Sus nodos son los parches de $\Z$, $V = \{\x_i\}$.
	\item Cada arista que une los nodos $\x_a$ y $\x_b$ tiene peso $\omega(\x_a,\; \x_b)$, $f = \omega$.
\end{itemize}
Sobre $G_\X$ se quiere resolver una variante del problema \textit{\textbf{NP}-completo} del viajero, conocido como \TSP/\footnote{Por sus siglas en ingl\'es \textit{traveling salesman problem}.} \cite{cormen2009introduction,ilavarasi2014variants}, buscando un camino que comience en un parche (nodo) cualquiera, pase por el resto de los parches una \'unica vez y cuya longitud es m\'inima.

\section{Algoritmo de reordenamiento de parches}

No se conoce ningún algoritmo con complejidad temporal polinomial para resolver el \TSP/, con lo cual en favor de lograr la eficiencia del esquema de la recuperaci\'on se seleccion\'o un algoritmo que encuentra una soluci\'on aproximada. El camino de parches que se obtiene puede no ser el de m\'inima longitud, pero se garantiza que ser\'a de las menores. En cambio, esta soluci\'on aproximada se computa en un tiempo polinomial, que en este caso ser\'a lineal con respecto a la cantidad de parches, o sea $O(\dim(\X))$.

\begin{algorithm}[h]
	\KwIn{Conjunto de parches de la imagen $\{\mathbf{x}_i\}_{i = 1}^M$, funci\'on $\omega$, $B$ y $\epsilon$.}
	\KwOut{Arreglo $\Omega$ de los \'indices que definen el ordenamiento.}
	\BlankLine
	\KwInit{$\Omega(1) \gets$ Un entero aleatorio en el intervalo $[1,\; M]$}
	\For{$k \gets 1$ \emph{\KwTo} $M - 1$} {
		$A_k \gets $ Conjunto de los \'indices de los $B \times B$ parches alrededor de $\x_{\Omega(k)}$\;
		\eIf{$|A_k \setminus \Omega| = 1$} {
			$\Omega(k + 1) \gets A_i \setminus \Omega$\;
		}{
			\eIf{$|A_k \setminus \Omega| \ge 2$}{
				Encontrar $\x_a, \x_b$ los parches m\'as ceranos a $\x_{\Omega(k)}$ tales que $a, b \in |A_k \setminus \Omega|$\;
			}{
				Encontrar $\x_a, \x_b$ los parches m\'as ceranos a $\x_{\Omega(k)}$ tales que $a, b \notin \Omega$\;
			}
			$\Omega(k + 1) \gets \left\{
				\begin{array}{ccc}
				\x_a &\mbox{con probabilidad}& p_a = \alpha e^{-\frac{\omega(\x_{j_{k - 1}},\; \x_a)}{\epsilon}}\\
				\x_b &\mbox{con probabilidad}& p_b = \alpha e^{-\frac{\omega(\x_{j_{k - 1}},\; \x_b)}{\epsilon}}\\
				\end{array}
			\right.$\;
		}
	}
	\Return{$\Omega$}\;
	\caption{Reordenamiento de parches.}
	\label{al:PRA}
\end{algorithm}

En este algoritmo primeramente se selecciona aleatoriamente un parche $\x_{j_0}$ por el cual comienza el camino. Luego se itera colocando en cada paso un parche hasta completar el camino. En la iteraci\'on $k$ se explora la vecindad de tamaño $\B \times \B$ en la matriz $\Z$ alrededor del parche $\x_{j_{k - 1}}$ (que es el \'ultimo que se ha puesto). Ahora bien, existen dos casos:
\begin{itemize}
\item Todos los parches en esta vecindad ya están en el camino: se busca fuera de la vecindad los dos parches $\x_a,\; \x_b$ que no pertenecen al camino y cuyas distancias $\omega$ a $\x_{j_{k - 1}}$ son las dos menores.
\item Si existen parches disponibles en esa vecindad: se buscan de forma an\'aloga los parches $\x_a,\; \x_b$, esta vez dentro de la vecindad.
\end{itemize}
Claramente si no es posible encontrar dos menores porque solo hay un parche disponible, entonces $\x_{j_k}$ ser\'ia ese \'unico parche. En cambio si se tienen $\x_a$ y $\x_b$ entonces:
\begin{equation}
	\x_{j_k} = \left\{
		\begin{array}{ccc}
		\x_a &\mbox{con probabilidad}& p_a = \alpha e^{-\frac{\omega(\x_{j_{k - 1}},\; \x_a)}{\epsilon}}\\
		\x_b &\mbox{con probabilidad}& p_b = \alpha e^{-\frac{\omega(\x_{j_{k - 1}},\; \x_b)}{\epsilon}}\\
		\end{array}
	\right.
	\label{eq:choosing_patch}
\end{equation}
donde $\alpha$ es tal que $p_a + p_b = 1$ y $\epsilon$ es un valor ajustable. Finalmente el conjunto de \'indices $\{j_i\}$ del camino de parches define la permutaci\'on $\P$ (ver definici\'on \ref{def:permutation}) que se busca. El pseudoc\'odigo se muestra en el algoritmo \ref{al:PRA}.

\section{Trabajo con subim\'agenes}
Tomando como $n$ el tamaño de los parches en este procedimiento, se tiene por el lema \ref{le:count_patches} que la cantidad de parches de la matriz $\Z$ es: 
\begin{equation}
	N_p = (N_1 - \sqrt{n} + 1)(N_2 - \sqrt{n} + 1)
	\label{eq:patches}
\end{equation}
De igual forma, por el lema \ref{le:count_patches_ieq} la cantidad de parches $N_p$ de $\Z$ es menor que el tamaño del vector $\z$, luego la dimensi\'on de la matriz $\P$ obtenida con algoritmo \ref{al:PRA} es $N_p \times N_p$. Lo anterior implica que el esquema inicial (figura \ref{fig:init_scheme}) solo ser\'ia aplicables a señales de tamaño $N_p$. Esto se puede apreciar claramente en el ejemplo \ref{ex:subimages}, donde $N = 16 > N_p = 9$.

\begin{example}[H]
	\[\Z = \left(
		\;\begin{matrix}
		\cline{2-4}
			a & \multicolumn{1}{|c}{b} & c & \multicolumn{1}{c|}{d}\\
			e & \multicolumn{1}{|c}{f} & g & \multicolumn{1}{c|}{h}\\
			i & \multicolumn{1}{|c}{j} & k & \multicolumn{1}{c|}{l}\\\cline{2-4}
			m & n & o & p\\
		\end{matrix}\;\;\;
	\right)
	\qquad\z = \left(
		\begin{array}{cccc|ccc|c|ccc|c|ccc|c}
			\cline{5-7}\cline{9-11}\cline{13-15}
			a & e & i & m & b & f & j & n & c & g & k & o & d & h & l & p\\
			\cline{5-7}\cline{9-11}\cline{13-15}
		\end{array}
	\right)^\intercal
	\]
	\[
	\X = \left(
		\;\begin{matrix}
			a & e & i & b & f & j & c & g & k\\
			e & i & m & f & j & n & g & k & o\\\hline
			\multicolumn{1}{|c}{b} & f & j & c & g & k & d & h & \multicolumn{1}{c|}{l}\\\hline
			f & j & n & g & k & o & h & l & p\\
		\end{matrix}\;
	\right)
	\]
	\caption{Subimagen de la matriz $\Z$ de $4 \times 4$, tomando como centro de los parches el tercer p\'ixel.}
	\label{ex:subimages}
\end{example}

Téngase en cuenta que la subimagen formada por los p\'ixeles centrales de cada parche es una señal de tamaño $N_p$ (ver ejemplo \ref{ex:subimages}), entonces es posible aplicarle el esquema inicial (figura \ref{fig:init_scheme}) para recuperar por completo esa subimagen. Considerando todos los posibles centros para los parches, se tiene un total de $n$ subim\'agenes. Si se recupera cada una de estas y se colocan en su posición natural en $\Z$, est\'a claro que todas se solapar\'ian, para ello se promedian los p\'ixeles solapados, y así se formar\'ia una imagen completa recuperada. 

Se denota por $\Ztilde_j$ a la subimagen formada por los centros de los parches, cuando el centro se encuentra en la posici\'on $j$ en cada parche. Luego se tienen las $n$ subim\'agenes: $\Ztilde_1,\; \Ztilde_2,\; \dots,\; \Ztilde_n$. Si se representa el vector de parches $X$ como una matriz, poniendo los parches como columnas, entonces cada fila de esta matriz es una submimagen en forma de vector (ver ejemplo \ref{ex:subimages}). Por lo tanto la subimagen $\Ztilde_j$ se encuentra en su forma de vector $\ztilde_j$ en la fila $j$ de la matriz $\X$. Cada una de estas señales se restauran usando $\ztilde_j$ en (\ref{eq:init_yhat}) en cambio de $\z$:
\begin{equation}
	\yhattilde_j = \P^{-1}\H(\ztilde_j^p) = \P^{-1}\H(\P\ztilde_j)
	\label{eq:subimage_yhat}
\end{equation}

Se modifica entonces el esquema inicial (figura \ref{fig:init_scheme}) para que se adapte al nuevo enfoque con subim\'agenes de la siguiente forma:
\begin{enumerate}
	\item A partir de $\Z$ se obtiene la matriz $\X$, poniendo los parches de $\Z$ como columnas (ver ejemplo \ref{ex:subimages}).
	\item Usando el algoritmo \ref{al:PRA} se obtiene $\P$ a partir de $\X$.
	\item A las señales de cada subimagen: $\ztilde_1,\; \ztilde_2,\; \dots,\; \ztilde_n$ (vectores fila de $\X$) se le aplica el esquema inicial mediante (\ref{eq:subimage_yhat}) tal como se muestra en la figura \ref{fig:subimage_scheme}.
	\item Se colocan los p\'ixeles de las subim\'agenes recuperadas: $\yhattilde_1,\; \yhattilde_2,\; \dots,\; \yhattilde_n$ en su posici\'on natural en $z$, para promediar los valores dentro de una misma posici\'on y obtener $\yhat$.
\end{enumerate}

\begin{figure}[H]
	\begin{equation*}
		\z\longrightarrow\left\{
		\def\arraystretch{2.2}
		\begin{array}{ccccccccccc}
			\ztilde_1 & \longrightarrow & \boxed{\P} & \longrightarrow & \boxed{\H} & \longrightarrow & \boxed{\P^{-1}} & \longrightarrow & \yhattilde_1\\
			\ztilde_2 & \longrightarrow & \boxed{\P} & \longrightarrow & \boxed{\H} & \longrightarrow & \boxed{\P^{-1}} & \longrightarrow & \yhattilde_2\\
			& & \huge\vdots &  & \huge\vdots &  & \huge\vdots & & & \\
			\ztilde_n & \longrightarrow & \boxed{\P} & \longrightarrow & \boxed{\H} & \longrightarrow & \boxed{\P^{-1}} & \longrightarrow & \yhattilde_n\\
		\end{array}
		\right\}\longrightarrow\yhat
	\end{equation*}
	\caption{Nuevo esquema con subim\'agenes.}
	\label{fig:subimage_scheme}
\end{figure}

\section{Esquema final}\label{sec:final_scheme}

Con el esquema presentado anteriormente (figura \ref{fig:subimage_scheme}) ya es posible realizar la recuperaci\'on de im\'agenes. Como esquema final se propone el uso de $K$ matrices de permutaci\'on diferentes, esto es posible debido a que el algoritmo \ref{al:PRA} no tiene un resultado \'unico para un $\X$ fijo. El mismo depende de algunas variables aleatorias que hacen que dos ejecuciones con los mismos par\'ametros generen dos matrices $\P$ distintas. El objetivo de usar varias matrices de permutaci\'on es realizar el esquema de la figura \ref{fig:subimage_scheme} con cada una de las $K$ matrices $\P_i$, obteniendo las im\'agenes recuperadas: $\yhat_1,\; \yhat_2,\; \dots,\; \yhat_K$. La imagen recuperada final $\yhat$ ser\'ia el promedio de las anteriores:
\begin{equation}
	\yhat = \frac{1}{K}\sum_{i = 1}^{K}\yhat_i
	\label{eq:final_yhat}
\end{equation} 
Con esta t\'ecnica se suaviza mejor la imagen recuperada, lo cual se asemeja al método \textit{cycle spinning}\footnote{M\'etodo conocido por su nombre en ingl\'es, que significa \textit{hilatura cíclica}.} \cite{coifman1995translation}. En resumen, el esquema final se realiza de la siguiente manera:

\newcommand{\subimageScheme}[1]{
\z\longrightarrow\left\{
\def\arraystretch{1.5}
\begin{array}{ccccccccccc}
	\ztilde_1 & \longrightarrow & \boxed{\P_{#1}} & \longrightarrow & \boxed{\H} & \longrightarrow & \boxed{\P^{-1}_{#1}} & \longrightarrow & \yhattilde_1\\
	\ztilde_2 & \longrightarrow & \boxed{\P_{#1}} & \longrightarrow & \boxed{\H} & \longrightarrow & \boxed{\P^{-1}_{#1}} & \longrightarrow & \yhattilde_2\\
	& & \huge\vdots &  & \huge\vdots &  & \huge\vdots & & & \\
	\ztilde_n & \longrightarrow & \boxed{\P_{#1}} & \longrightarrow & \boxed{\H} & \longrightarrow & \boxed{\P^{-1}_{#1}} & \longrightarrow & \yhattilde_n\\
\end{array}
\right\}\longrightarrow\yhat_{#1}
}

\begin{figure}[H]
	\centering
	\resizebox{0.9\textwidth}{!}{$
		\left.
		\begin{array}{c}
			\subimageScheme{1}\\\\
			\subimageScheme{2}\\\\
			\huge\vdots\\\\
			\subimageScheme{K}\\
		\end{array}
		\right\}\overset{(\ref{eq:final_yhat})}{\xrightarrow{\hspace{1.5cm}}}\yhat
	$}
	\caption{Esquema final con $K$ matrices de permutaci\'on.}
	\label{fig:final_scheme}
\end{figure}

\begin{enumerate}
	\item A partir de la imagen incompleta $\Z$ se genera la matriz $\X$ poniendo los parches como columnas (ver ejemplo \ref{ex:subimages}).
	\item El algoritmo \ref{al:PRA} se ejecuta $K$ veces con los mismos par\'ametros: $\X$, $\omega$, $B$ y $\epsilon$ obteniendo $K$ matrices de permutaci\'on: $\P_1,\; \P_2,\; \dots,\; \P_K$.
	\item Se usa cada permutaci\'on una vez y se realiza el esquema de la figura \ref{fig:subimage_scheme} para obtener $K$ señales recuperadas: $\yhat_1,\; \yhat_2,\; \dots,\; \yhat_K$ como se muestra en la figura \ref{fig:final_scheme}.
	\item Estas señales se promedian y se obtiene $\yhat$ tal como se expresa en (\ref{eq:final_yhat}).
\end{enumerate}

\subsection{Par\'ametros del esquema}
Las \'unicas incógnitas pendientes de este esquema son: el operador de suavidad $\H$, la funci\'on de distancia $\omega$ y el valor ajustable $\epsilon$. Este \'ultimo es un valor que no es fijo y se usa para evitar errores num\'ericos en el momento de realizar la exponenciaci\'on en (\ref{eq:choosing_patch}). Es conocido que el universo de números representables en una aritmética de punto flotante es finito \cite{conte2017elementary}. Los problemas m\'as comunes son asociados a la precisión limitada\footnote{En la mayoría de los lenguajes de programación la precisión de los n\'umeros de punto flotante no excede las 15 cifras.} tales como las operaciones que resultan en valores muy cercanos a cero. En el caso espec\'ifico de (\ref{eq:choosing_patch}), debemos evitar que el exponente no sea muy grande, para ello se divide $\omega$ por un valor lo suficientemente grande para cualquiera de sus evaluaciones, ese ser\'ia el valor adecuado de $\epsilon$. Ahora bien, tanto $\H$ como $\omega$ pueden quedar a elecci\'on del usuario, no obstante se definen a continuaci\'on los usados para el Cap\'itulo \ref{chapter:results}.

La funci\'on $\omega$ entre dos parches $\x_a$ y $\x_b$ se asume como el promedio de los cuadrados de las diferencias entre los p\'ixeles que est\'an en la misma posici\'on en ambos parches y que ambos son p\'ixeles con valor conocido. Escrito formalmente: sea $S_i$ el conjunto de \'indices de los p\'ixeles conocidos del parche $\x_i$ para todo $1 \le i \le N_p$ entonces:
\begin{equation}
	\omega(\x_a, \x_b) = \frac{\sum_{t \in S_a \cap S_b} (\x_a[t] - \x_b[t])^2}{|S_a \cap S_b|}
	\label{eq:omega}
\end{equation}
Cuando $S_a \cap S_b = \emptyset$ se indetermina el valor de la funci\'on, en este caso se toma un valor lo suficientemente grande en su lugar. Este convenio se asume para evitar colocar dos parches consecutivos sin relaci\'on en el ordenamiento suave. Una soluci\'on simple es tomar ese valor suficientemente grande como $(4\mathbf{MAX}^2_\Z + 1)$, donde $\mathbf{MAX_Z}$ es el m\'aximo de los valores absolutos de los elementos en la matriz $\Z$. Se puede demostrar que $4\mathbf{MAX}^2_\Z \ge \omega(\x_a, \x_b)$ para cualesquiera parches $\x_a$ y $\x_b$ tales que $S_a \cap S_b \not= \emptyset$:
\begin{equation*}
	\def\arraystretch{2.5}
	\begin{array}{rcl}
		\displaystyle
		\omega(\x_a, \x_b) = \frac{\sum_{t \in S_a \cap S_b} (\x_a[t] - \x_b[t])^2}{|S_a \cap S_b|}
		&\le& \displaystyle\frac{\sum_{t \in S_a \cap S_b} (|\x_a[t]| + |\x_b[t]|)^2}{|S_a \cap S_b|}\\
		&\le& \displaystyle\frac{|S_a \cap S_b| (2\mathbf{MAX_Z})^2}{|S_a \cap S_b|} = 4\mathbf{MAX}^2_\Z \quad\square
	\end{array}
\end{equation*}

Como operador de suavidad $\H$ se escoge la interpolaci\'on polinomial por tramos (\textit{splines}) usando polinomios de a lo sumo grado $3$ y con condiciones de suavidad hasta la derivada de segundo orden en los extremos de los subintervalos \cite{burden1996analisis}. Este tipo de interpolaci\'on evita el conocido fen\'omeno de \textit{Runge} cuando se usan polinomios de alto grado \cite{quarteroni2014approximation}. Por lo tanto se obtiene una aproximación suave y m\'as precisa (menor error de interpolación).

\subsection{Costo computacional del esquema}

Se analiza primeramente la complejidad temporal del esquema final. Siguiendo cada una de sus fases:
\begin{itemize}
	\item Construir $\X$ se hace en $O(nN_p)$.
	\item Ejecutar el algoritmo \ref{al:PRA} para obtener la matriz de permutaci\'on es $O(N_pB^2n)$, pues por cada parche se busca en su vecindad de $B \times B$ comparando con $\omega$, que en nuestro caso tiene un costo de evaluaci\'on de $O(n)$.
	\item Aplicar la permutaci\'on obtenida a las $n$ subim\'agenes se realiza en $O(nN_p)$.
	\item Aplicar el operador $\H$ (\textit{splines} c\'ubicos) a cada resultado anterior, se logra en $O(nN_p)$.
	\item Aplicar la permutaci\'on inversa para obtener las $n$ señales recuperadas también se realiza en $O(nN_p)$.
	\item Acoplar las $n$ subim\'agenes en la imagen completa se realiza en $O(nN)$.
	\item Ejecutar los 5 pasos anteriores $K$ veces distintas para obtener $K$ im\'agenes completas recuperadas: $K[O(N_pB^2n) + O(nN_p) + O(nN)]$
	\item Promediar las $K$ im\'agenes recuperadas para obtener la final: $O(KN)$
\end{itemize}
Ya que $N_p < N$, se concluye que la complejidad temporal del esquema final es:
\begin{equation}
	O(nN) + K[O(NB^2n) + O(nN)] + O(KN) = \boxed{O(KNB^2n)}
	\label{eq:temporal_complexity}
\end{equation}

En el caso de la complejidad espacial, de igual forma, se analiza cada una de las fases del esquema final:
\begin{itemize}
	\item Almacenar $\X$ ocupa $O(nN_p)$ de memoria.
	\item Una permutaci\'on puede almacenarse en $O(Np)$ de memoria.
	\item Aplicar la permutaci\'on, luego el operador $\H$ y finalmente aplicar la permutaci\'on inversa a cada subimagen puede realizarse usando $O(nNp)$ de memoria.
	\item Almacenar la imagen que resulta de acoplar las $n$ subim\'agenes ocupa $O(N)$ de memoria.
	\item Realizar las $K$ restauraciones para promediarlas en una final usa $O(KN)$ de memoria.
\end{itemize}
La memoria total a usar resulta en:
\begin{equation}
	O(nN_p) + [O(Np) + O(nN_p) + O(N)] + O(KN) = \boxed{O(N(K + n))}
	\label{eq:spacial_complexity}
\end{equation}


Los valores de $K$ y $n$ son usualmente pequeños y no incrementan de forma drástica el tiempo de ejecuci\'on de la recuperaci\'on. El tamaño de la imagen $N$ es algo con lo que pr\'acticamente no se puede lidiar, im\'agenes de mucha resoluci\'on afectan de forma considerable la complejidad temporal. Finalmente, en el caso de $B$ el tamaño de la vecindad que se explora, como se puede notar este se eleva al cuadrado, lo que sugiere usar valores bastante pequeños. Sin duda este par\'ametro es el m\'as cr\'itico con respecto a la complejidad temporal, en los casos que se necesite aumentar su valor para una mejor calidad de la restauraci\'on limitar\'ia mucho el rango de tamaños de im\'agenes a procesar. Con respecto a la complejidad espacial, los valores a tener en cuenta son $N$ y $n$, usar parches muy grandes en im\'agenes de grandes dimensiones puede llenar considerablemente la memoria.


